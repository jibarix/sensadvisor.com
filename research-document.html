<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TECHNICAL REPORT: Core Architectures of Text Diffusion Models</title>
    
    <!-- Google Fonts - Source Code Pro -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- Microsoft Clarity Analytics -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "rdalx1jkyh");
    </script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Source Code Pro', monospace;
            background: #ffffff;
            color: #000000;
            line-height: 1.6;
            font-size: 14px;
        }

        .document-container {
            max-width: 800px;
            margin: 0 auto;
            background: #ffffff;
            min-height: 100vh;
            border-left: 2px solid #000000;
            border-right: 2px solid #000000;
        }

        /* Document Header */
        .document-header {
            background: #000000;
            color: #ffffff;
            padding: 20px;
            text-align: center;
            border-bottom: 4px solid #000000;
        }

        .classification {
            font-size: 12px;
            font-weight: 300;
            letter-spacing: 2px;
            margin-bottom: 10px;
        }

        .document-title {
            font-size: 18px;
            font-weight: 700;
            margin-bottom: 5px;
            letter-spacing: 1px;
        }

        .document-subtitle {
            font-size: 14px;
            font-weight: 400;
            margin-bottom: 15px;
        }

        .document-meta {
            font-size: 11px;
            border-top: 1px solid #ffffff;
            padding-top: 10px;
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
        }

        .meta-item {
            text-align: center;
        }

        /* Navigation */
        .nav-header {
            background: #ffffff;
            border-bottom: 2px solid #000000;
            padding: 15px 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .nav-back {
            color: #000000;
            text-decoration: none;
            font-weight: 600;
            border: 2px solid #000000;
            padding: 8px 16px;
            transition: all 0.2s ease;
        }

        .nav-back:hover {
            background: #000000;
            color: #ffffff;
        }

        .doc-info {
            font-size: 12px;
            font-weight: 400;
        }

        /* Content Area */
        .document-content {
            padding: 30px;
        }

        .section-divider {
            border: none;
            border-top: 2px solid #000000;
            margin: 30px 0;
        }

        .section-divider.heavy {
            border-top: 4px solid #000000;
            margin: 40px 0;
        }

        /* Typography */
        h1 {
            font-size: 20px;
            font-weight: 700;
            margin-bottom: 20px;
            border-bottom: 2px solid #000000;
            padding-bottom: 10px;
            letter-spacing: 1px;
            text-transform: uppercase;
        }

        h2 {
            font-size: 16px;
            font-weight: 600;
            margin: 30px 0 15px 0;
            border-left: 4px solid #000000;
            padding-left: 15px;
        }

        h3 {
            font-size: 14px;
            font-weight: 600;
            margin: 25px 0 10px 0;
            text-decoration: underline;
        }

        h4 {
            font-size: 13px;
            font-weight: 600;
            margin: 20px 0 8px 0;
            font-style: italic;
        }

        p {
            margin-bottom: 15px;
            text-align: justify;
        }

        /* Lists */
        ul, ol {
            margin: 15px 0 15px 30px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Special Elements */
        .emphasis {
            font-weight: 700;
            background: #000000;
            color: #ffffff;
            padding: 2px 4px;
        }

        .reference {
            font-style: italic;
            color: #000000;
        }

        .code-block {
            background: #f0f0f0;
            border: 2px solid #000000;
            padding: 15px;
            font-family: 'Source Code Pro', monospace;
            margin: 15px 0;
            overflow-x: auto;
        }

        /* Critical Warning Box */
        .critical-warning {
            background: #ffffff;
            border: 3px solid #000000;
            padding: 20px;
            margin: 25px 0;
            position: relative;
        }

        .critical-warning::before {
            content: "CRITICAL IMPLEMENTATION WARNING";
            position: absolute;
            top: -12px;
            left: 15px;
            background: #000000;
            color: #ffffff;
            padding: 4px 12px;
            font-size: 12px;
            font-weight: 700;
            letter-spacing: 1px;
        }

        .critical-warning h4 {
            color: #000000;
            font-size: 14px;
            margin: 0 0 10px 0;
            font-weight: 700;
        }

        .critical-warning p {
            margin-bottom: 10px;
            font-size: 13px;
        }

        .warning-code {
            background: #f0f0f0;
            border: 2px solid #000000;
            padding: 10px;
            font-family: 'Source Code Pro', monospace;
            font-size: 12px;
            margin: 10px 0;
        }

        .incorrect-code {
            border-left: 6px solid #000000;
        }

        .correct-code {
            border-left: 6px solid #000000;
        }

        /* Breakthrough Box */
        .breakthrough {
            background: #ffffff;
            border: 3px solid #000000;
            padding: 20px;
            margin: 25px 0;
            position: relative;
        }

        .breakthrough::before {
            content: "BREAKTHROUGH VALIDATION";
            position: absolute;
            top: -12px;
            left: 15px;
            background: #000000;
            color: #ffffff;
            padding: 4px 12px;
            font-size: 12px;
            font-weight: 700;
            letter-spacing: 1px;
        }

        /* Special Sections */
        .abstract {
            border: 2px solid #000000;
            padding: 20px;
            margin: 20px 0;
            background: #ffffff;
        }

        .abstract h2 {
            margin-top: 0;
            text-align: center;
            border: none;
            padding: 0;
        }

        /* References Section */
        .references {
            border-top: 4px solid #000000;
            padding-top: 20px;
            margin-top: 40px;
        }

        .reference-item {
            margin-bottom: 15px;
            padding-left: 20px;
            text-indent: -20px;
            font-size: 12px;
        }

        /* Footer */
        .document-footer {
            background: #000000;
            color: #ffffff;
            padding: 20px;
            text-align: center;
            margin-top: 40px;
            font-size: 12px;
        }

        .footer-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
            margin-bottom: 10px;
        }

        /* Print Styles */
        @media print {
            .nav-header {
                display: none;
            }
            
            .document-container {
                border: none;
                box-shadow: none;
            }
            
            body {
                font-size: 12px;
            }
        }

        /* Mobile Responsiveness */
        @media (max-width: 768px) {
            .document-container {
                border-left: none;
                border-right: none;
            }
            
            .document-content {
                padding: 20px;
            }
            
            .document-meta {
                grid-template-columns: 1fr;
                gap: 10px;
            }
            
            .footer-grid {
                grid-template-columns: 1fr;
                gap: 10px;
            }
            
            .nav-header {
                flex-direction: column;
                gap: 10px;
                text-align: center;
            }

            .critical-warning, .breakthrough {
                padding: 15px;
                margin: 20px 0;
            }

            .critical-warning::before, .breakthrough::before {
                font-size: 11px;
                padding: 3px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="document-container">
        <!-- Document Header -->
        <header class="document-header">
            <div class="classification">TECHNICAL RESEARCH DOCUMENT</div>
            <h1 class="document-title">CORE ARCHITECTURES OF TEXT DIFFUSION MODELS</h1>
            <div class="document-subtitle">A Developer's Guide</div>
            <div class="document-meta">
                <div class="meta-item">
                    <strong>DOCUMENT ID:</strong><br>
                    TDM_DEV_GUIDE_v0.8
                </div>
                <div class="meta-item">
                    <strong>AUTHOR:</strong><br>
                    Jorge A. Arroyo
                </div>
                <div class="meta-item">
                    <strong>STATUS:</strong><br>
                    RELEASED
                </div>
            </div>
        </header>

        <!-- Navigation -->
        <nav class="nav-header">
            <a href="index.html" class="nav-back">← RETURN TO MAIN SITE</a>
            <div class="doc-info">SENS ADVISOR TECHNICAL RESEARCH</div>
        </nav>

        <!-- Document Content -->
        <main class="document-content">
            <!-- Abstract -->
            <section class="abstract">
                <h2>EXECUTIVE SUMMARY</h2>
                <p>An analysis of recent research reveals two dominant architectural paradigms for text generation diffusion models: <span class="emphasis">Discrete Diffusion</span> and <span class="emphasis">Continuous Diffusion</span>. While both are built on the foundational principle of reversing a corruption process, their internal mechanics differ significantly. This guide outlines a core two-component architecture with five essential subcomponents, providing a clear and consistent understanding of both approaches for developers.</p>
                
                <p>The central idea is a two-stage process: A <span class="emphasis">fixed, non-learned Forward Process</span> systematically corrupts clean text into a simple, known distribution, and a <span class="emphasis">learned Reverse Process</span> starts from that simple distribution and iteratively refines it back into coherent, clean text.</p>
            </section>

            <!-- Breakthrough Validation -->
            <section class="breakthrough">
                <h2>BREAKTHROUGH VALIDATION: LLaDA (2025)</h2>
                <p>The theoretical foundations outlined in this guide received major validation with the release of <span class="emphasis">LLaDA (Large Language Diffusion with mAsking)</span> by Nie et al. (2025). LLaDA represents the first discrete diffusion language model to achieve competitive performance with strong autoregressive LLMs at scale.</p>
                
                <p><span class="emphasis">Scale Achievement:</span> LLaDA 8B, trained from scratch on 2.3T tokens, achieves performance competitive with LLaMA3 8B across diverse benchmarks including language understanding, mathematics, code generation, and Chinese language tasks.</p>
                
                <p><span class="emphasis">Key Validations:</span></p>
                <ul>
                    <li><span class="emphasis">Scalability:</span> Proves discrete diffusion scales effectively to 8B parameters and beyond</li>
                    <li><span class="emphasis">Competitive Performance:</span> Matches or exceeds strong AR baselines on standard benchmarks</li>
                    <li><span class="emphasis">Unique Capabilities:</span> Addresses the "reversal curse," outperforming GPT-4o on reversal reasoning tasks</li>
                    <li><span class="emphasis">Instruction Following:</span> Demonstrates strong chat and instruction-following abilities after supervised fine-tuning</li>
                </ul>
                
                <p>This breakthrough establishes discrete diffusion as a viable alternative to autoregressive modeling for large-scale language generation.</p>
            </section>

            <hr class="section-divider heavy">

            <!-- Main Content -->
            <h1>Current Architectural Limitations & Core Trade-offs</h1>
            
            <p>Before diving into the components, it's crucial to understand the high-level trade-offs between autoregressive (AR) and non-autoregressive (NAR) models like diffusion. The choice between them often comes down to a fundamental decision between optimizing for <span class="emphasis">compute efficiency</span> or <span class="emphasis">data efficiency</span>.</p>

            <h2>Autoregressive (AR) Models: Optimized for Compute</h2>
            
            <p>AR models are highly optimized for computational efficiency, but this comes with limitations.</p>

            <ul>
                <li><span class="emphasis">Strengths:</span> The sequential, left-to-right process with teacher forcing and causal masking is exceptionally efficient on modern hardware, achieving a high signal-to-FLOPs ratio during training.</li>
                <li><span class="emphasis">Limitations:</span>
                    <ul>
                        <li><span class="emphasis">Error Propagation & Exposure Bias:</span> An early mistake can't be corrected and often leads to a cascade of errors, degrading the quality of the entire sequence <span class="reference">(Tang et al., 2023)</span>.</li>
                        <li><span class="emphasis">Restrictive Inductive Bias:</span> The strict causal (left-to-right) structure prevents the model from learning from the full bidirectional context of the data.</li>
                        <li><span class="emphasis">Slow Inference:</span> Generating a sequence of length N requires N sequential forward passes, making inference slow.</li>
                    </ul>
                </li>
            </ul>

            <h2>Diffusion Models (NAR): Optimized for Data</h2>
            
            <p>Diffusion models are "super data learners" that trade higher computational costs for a deeper understanding of the training data.</p>

            <ul>
                <li><span class="emphasis">Strengths:</span>
                    <ul>
                        <li><span class="emphasis">Superior Data Efficiency:</span> By repeatedly training on the same data with different random masks, diffusion models can extract significantly more information from a fixed-size dataset.</li>
                        <li><span class="emphasis">Bidirectional Modeling:</span> The masking objective allows the model to learn from the full bidirectional context of a sequence, removing the restrictive causal bias of AR models.</li>
                    </ul>
                </li>
                <li><span class="emphasis">Limitations:</span>
                    <ul>
                        <li><span class="emphasis">High Computational Cost:</span> The diffusion objective is computationally "super-dense," requiring more FLOPs per token during both training and inference.</li>
                    </ul>
                </li>
            </ul>

            <hr class="section-divider heavy">

            <h1>The Two Core Components</h1>

            <p>Text diffusion models fundamentally consist of two complementary processes that work together to enable generation:</p>

            <h2>Core Component 1: The Forward Process (Data → Noise)</h2>
            <p>The forward process systematically corrupts clean text into a simple, tractable distribution. This is a fixed, non-learned process that creates the learning task for the reverse process. It consists of three essential subcomponents that work together to define how clean data becomes noise.</p>

            <h2>Core Component 2: The Reverse Process (Noise → Data)</h2>
            <p>The reverse process learns to invert the forward corruption, step-by-step, to generate new data. This is the learned, generative core of the model. It consists of two essential subcomponents that define how the model learns to denoise and what objective guides this learning.</p>

            <hr class="section-divider heavy">

            <h1>Core Component 1: The Forward Process</h1>

            <h2>Subcomponent 1A: Input Representation</h2>
            
            <p>This subcomponent determines how raw text is converted into a format suitable for the diffusion process.</p>
            
            <p><span class="emphasis">Discrete Diffusion</span> operates directly on tokenized text, using token IDs from a standard vocabulary (e.g., BPE, WordPiece). <span class="emphasis">Continuous Diffusion</span> converts discrete tokens into continuous vector representations, typically through embeddings or contextualized encodings from pre-trained models.</p>

            <h2>Subcomponent 1B: The Corruption Process</h2>

            <h3>Discrete Diffusion</h3>
            
            <p>The corruption process operates as a fixed Markov chain, starting with a clean text sequence (x₀) and progressively replacing discrete tokens with a special [MASK] token until the sequence is fully degraded. This approach directly connects the diffusion framework to the highly successful Masked Language Modeling (MLM) paradigm.</p>

            <!-- Critical Implementation Detail -->
            <div class="critical-warning">
                <h4>Critical Implementation Detail: Variable Masking Ratios</h4>
                
                <p>LLaDA (Nie et al., 2025) demonstrates that <span class="emphasis">variable masking ratios per sequence</span> are essential for optimal performance:</p>
                
                <p><strong>Variable Masking (LLaDA Approach):</strong></p>
                <div class="warning-code correct-code">
- Each sequence in a training batch gets a different corruption ratio
- Sampled as: t ~ U[0,1] per sequence  
- Trains model to handle diverse corruption levels simultaneously
                </div>
                
                <p><strong>Why Not Fixed Ratios:</strong></p>
                <div class="warning-code incorrect-code">
- Fixed ratios train the model for only one specific infilling task
- Variable ratios create a more robust, generalizable model
- Essential for achieving competitive performance at scale
                </div>
                
                <p><strong>Implementation:</strong> Set <code>single_ratio_per_sequence = false</code> in your diffusion configuration.</p>
            </div>

            <h3>Continuous Diffusion</h3>
            
            <p>This approach first maps tokens into a continuous vector space using contextual encodings from pre-trained models (e.g., BERT). The forward process then gradually adds Gaussian noise to these encodings according to a predefined schedule until they become pure noise (zT).</p>

            <p><span class="emphasis">Shabalin et al. (2025)</span> demonstrate that using contextual encodings is superior to using context-free embeddings, providing the diffusion model with a more suitable latent space for training.</p>

            <h2>Subcomponent 1C: The Corruption Schedule</h2>

            <h3>Discrete Diffusion</h3>

            <div class="critical-warning">
                <h4>CRITICAL DISTINCTION: Training vs Inference Schedules</h4>
                
                <p>Recent research, particularly LLaDA (Nie et al., 2025), clarifies that training and inference use different scheduling approaches:</p>
                
                <p><strong>Training Schedule:</strong></p>
                <div class="warning-code correct-code">
- Uses uniform sampling of corruption ratios: t ~ U[0,1] for each sequence
- Each training example gets a different randomly sampled corruption level
- Implementation: mask_ratio = torch.rand(batch_size)
                </div>
                
                <p><strong>Inference Schedule:</strong></p>
                <div class="warning-code correct-code">
- Uses cosine discretization for the reverse process steps
- Formula: t(i) = cos²(π/2 × (1 - i/T)) for step i of T total steps
- Creates equally difficult denoising steps for optimal sampling quality
                </div>
                
                <p><strong>Why This Matters:</strong> Training with uniform sampling ensures robust learning across all corruption levels. Inference with cosine scheduling ensures optimal generation quality. Zhang (2025) proves cosine schedule is Fisher-Rao optimal for masked discrete diffusion.</p>
            </div>

            <h3>Continuous Diffusion</h3>
            
            <p>The schedule defines how much Gaussian noise is added at each step t of the forward process. Standard schedules from image diffusion have been found to be suboptimal for text. <span class="emphasis">Shabalin et al. (2025)</span> propose a <span class="emphasis">tan-d noise scheduler</span> designed to introduce a significantly higher and more consistent level of noise across all timesteps.</p>

            <hr class="section-divider heavy">

            <h1>Core Component 2: The Reverse Process</h1>

            <h2>Subcomponent 2A: The Denoising Network</h2>

            <h3>Discrete Diffusion</h3>
            
            <p>A neural network (typically a Transformer) learns to predict the original tokens at masked positions. The reverse process can operate in multiple steps, iteratively replacing masked tokens with predictions, often with remasking strategies that refine uncertain predictions over several iterations.</p>

            <p><span class="emphasis">Sahoo et al. (2024)</span> introduced confidence-based remasking, where the model iteratively unmasks the most confident predictions while remasking uncertain ones, significantly improving generation quality.</p>

            <h3>Continuous Diffusion</h3>
            
            <p>A neural network learns to denoise the corrupted latent vectors, typically involving predicting either the noise to be removed or the clean latent vectors directly. <span class="emphasis">Shabalin et al. (2025)</span> demonstrate that using a sophisticated encoder-denoiser-decoder architecture significantly improves performance.</p>

            <h2>Subcomponent 2B: The Objective Function</h2>

            <h3>Discrete Diffusion</h3>

            <div class="critical-warning">
                <h4>Correct Loss Function Implementation</h4>
                
                <p>The correct, theoretically grounded loss function for a sequence of N tokens is:</p>
                
                <div class="warning-code correct-code">
L∞(N) = ∫₀¹ [α'ₜ/(1-αₜ)] E_q(xₜ|x₀) [∑_{n:xₜ⁽ⁿ⁾=m} (x₀⁽ⁿ⁾)ᵀ log μθ⁽ⁿ⁾(xₜ,t)] dt
                </div>
                
                <p><strong>Key Components:</strong></p>
                <ul>
                    <li>μθ⁽ⁿ⁾(xₜ,t): Your neural network predicting probability distribution of original n-th token</li>
                    <li>αₜ: The masking schedule (e.g., αₜ = 1-t for linear schedule)</li>
                    <li>α'ₜ/(1-αₜ): Crucial time-dependent reweighting factor</li>
                </ul>
                
                <p><strong>CRITICAL:</strong> Omitting the time-dependent reweighting factor leads to an incorrect loss formulation that does not faithfully optimize the data's log-likelihood and makes comparisons with AR models fundamentally unfair.</p>
            </div>

            <h3>Continuous Diffusion</h3>
            
            <p>The objective is typically a regression-style loss. The denoising network is trained by minimizing the mean-squared error (MSE) between the network's prediction of the clean latent vectors and the true clean latent vectors.</p>

            <hr class="section-divider heavy">

            <h1>Advanced Sampling: Multiple Remasking Strategies</h1>

            <p>LLaDA introduces multiple remasking strategies for different use cases, moving beyond simple random remasking:</p>

            <h2>Random Remasking (Algorithm 4)</h2>
            <ul>
                <li>Pure random selection of tokens to remask at each step</li>
                <li>Simplest approach, good baseline performance</li>
                <li><span class="emphasis">Use case:</span> Base models, general text generation</li>
            </ul>

            <h2>Low-Confidence Remasking (Algorithm 5)</h2>
            <ul>
                <li>Remask tokens with lowest prediction confidence</li>
                <li>Significantly improves generation quality</li>
                <li><span class="emphasis">Use case:</span> When quality is more important than speed</li>
            </ul>

            <h2>Semi-Autoregressive Remasking</h2>
            <ul>
                <li>Divide sequence into blocks, generate left-to-right between blocks</li>
                <li>Apply diffusion within each block</li>
                <li><span class="emphasis">Use case:</span> Instruction-following models, structured generation</li>
            </ul>

            <p><span class="emphasis">Implementation Insight:</span> LLaDA shows that remasking strategy should be task-dependent, with base models preferring confidence-based approaches and instruct models benefiting from semi-autoregressive strategies.</p>

            <hr class="section-divider heavy">

            <h1>Implementation Considerations for Developers</h1>

            <h2>Choosing Between Discrete and Continuous</h2>

            <h3>Discrete Diffusion</h3>
            <p>Recommended for developers who:</p>
            <ul>
                <li>Want direct compatibility with existing NLP tokenization pipelines</li>
                <li>Need interpretable intermediate states during generation</li>
                <li>Are working with limited computational resources (generally more efficient)</li>
                <li>Want to leverage existing masked language modeling knowledge</li>
            </ul>

            <h3>Continuous Diffusion</h3>
            <p>Recommended for developers who:</p>
            <ul>
                <li>Need fine-grained control over the generation process</li>
                <li>Are working with rich, contextual representations</li>
                <li>Can afford higher computational costs for potentially better quality</li>
                <li>Want to experiment with novel noise injection strategies</li>
            </ul>

            <h2>Scaling Lessons from LLaDA</h2>

            <h3>Architecture Scaling</h3>
            <ul>
                <li>Standard Transformer components (RMSNorm, SwiGLU, RoPE) work well for discrete diffusion</li>
                <li>No special architectural modifications needed beyond bidirectional attention</li>
                <li>Scales to 8B parameters using similar compute budgets as autoregressive models</li>
            </ul>

            <h3>Training Scaling</h3>
            <ul>
                <li><span class="emphasis">Batch sizes:</span> LLaDA used 1280 (much larger than typical small-scale experiments)</li>
                <li><span class="emphasis">Learning rates:</span> 4×10⁻⁴ peak (higher than many AR models due to bidirectional objective)</li>
                <li><span class="emphasis">Optimization:</span> Standard AdamW with cosine decay works well</li>
            </ul>

            <h2>Advanced Technique: Accelerating Inference with Speculative Sampling</h2>

            <p>A major drawback of diffusion models is their slow inference speed due to the iterative nature of the reverse process. <span class="emphasis">Speculative sampling</span>, adapted for diffusion models by De Bortoli et al. (2025), offers a promising solution.</p>

            <p><span class="emphasis">The Core Idea:</span> Instead of running the expensive, high-quality "target" model for every single generation step, a faster, lower-quality "draft" model proposes a sequence of future steps. The target model then verifies these proposed steps in a single parallel pass, accepting or rejecting them. This can reduce the number of required evaluations by 50% or more without any loss in sample quality.</p>

            <h3>Drafting Strategies for Developers</h3>
            <ul>
                <li><span class="emphasis">Independent Draft Model:</span> Use a separate, smaller, and faster diffusion model as the draft model.</li>
                <li><span class="emphasis">Frozen Target Draft Model:</span> Use the output of the target model from the first step as a "frozen" prediction for all subsequent steps in a window. This requires no extra training and can be implemented out-of-the-box.</li>
            </ul>

            <hr class="section-divider heavy">

            <!-- References Section -->
            <section class="references">
                <h1>References</h1>
                
                <div class="reference-item">Austin, J., Johnson, D. D., Ho, J., Tarlow, D., & van den Berg, R. (2021). Structured denoising diffusion models in discrete state-spaces. In <em>Advances in Neural Information Processing Systems, 34</em>, 17981–17993.</div>
                
                <div class="reference-item">Chen, J., Zhang, A., Li, M., Smola, A., & Yang, D. (2023). A cheaper and better diffusion language model with soft-masked noise. <em>arXiv preprint arXiv:2304.04746</em>.</div>
                
                <div class="reference-item">De Bortoli, V., Galashov, A., Gretton, A., & Doucet, A. (2025). Accelerated diffusion models via speculative sampling. In <em>Proceedings of the 42nd International Conference on Machine Learning</em>.</div>
                
                <div class="reference-item">Gong, S., Li, M., Feng, J., Wu, Z., & Kong, L. (2023). DiffuSeq-v2: Bridging discrete and continuous text spaces for accelerated Seq2Seq diffusion models. In <em>Findings of the Association for Computational Linguistics: EMNLP 2023</em> (pp. 9868-9875).</div>
                
                <div class="reference-item">Li, Y., Zhou, K., Zhao, W. X., & Wen, J.-R. (2023). Diffusion models for non-autoregressive text generation: A survey. In <em>Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI-23)</em> (pp. 6692-6701).</div>
                
                <div class="reference-item">Ni, J., et al. (2025). Diffusion language models are super data learners. <em>Blog Post</em>. Retrieved from https://jinjieni.notion.site/Diffusion-Language-Models-are-Super-Data-Learners</div>
                
                <div class="reference-item">Nie, S., Zhu, F., You, Z., Zhang, X., Ou, J., Hu, J., Zhou, J., Lin, Y., Wen, J.-R., & Li, C. (2025). Large Language Diffusion Models. <em>arXiv preprint arXiv:2502.09992</em>.</div>
                
                <div class="reference-item">Prabhudesai, M., Wu, M., Zadeh, A., Fragkiadaki, K., & Pathak, D. (2025). Diffusion beats autoregressive in data-constrained settings. <em>arXiv preprint arXiv:2507.15857</em>.</div>
                
                <div class="reference-item">Sahoo, S. S., Arriola, M., Schiff, Y., Gokaslan, A., Marroquin, E., Chiu, J. T., Rush, A., & Kuleshov, V. (2024). Simple and effective masked diffusion language models. In <em>Advances in Neural Information Processing Systems, 37</em>.</div>
                
                <div class="reference-item">Shabalin, A., Meshchaninov, V., Chimbulatov, E., Lapikov, V., Kim, R., Bartosh, G., Molchanov, D., Markov, S., & Vetrov, D. (2025). TEncDM: Understanding the Properties of the Diffusion Model in the Space of Language Model Encodings.</div>
                
                <div class="reference-item">Shi, J., Han, K., Wang, Z., Doucet, A., & Titsias, M. K. (2025). Simplified and generalized masked diffusion for discrete data. In <em>Advances in Neural Information Processing Systems, 38</em>.</div>
                
                <div class="reference-item">Tang, C., Zhu, F., Huang, Z., & Liu, X. (2023). Denoising text generation by learning to reconcile predictions at different timesteps. <em>arXiv preprint arXiv:2310.13308</em>.</div>
                
                <div class="reference-item">Yi, X., Zhang, W., Wang, T., Li, L., & Yang, J. (2024). A comprehensive survey of diffusion models for text generation. <em>arXiv preprint arXiv:2401.12345</em>.</div>
                
                <div class="reference-item">Zhang, L. (2025). The cosine schedule is Fisher-Rao-optimal for masked discrete diffusion models. <em>arXiv preprint arXiv:2508.04884</em>.</div>
            </section>
        </main>

        <!-- Document Footer -->
        <footer class="document-footer">
            <div class="footer-grid">
                <div>
                    <strong>DOCUMENT ID:</strong><br>
                    TDM_DEV_GUIDE_v0.8
                </div>
                <div>
                    <strong>CLASSIFICATION:</strong><br>
                    TECHNICAL RESEARCH
                </div>
                <div>
                    <strong>AUTHOR:</strong><br>
                    JORGE A. ARROYO
                </div>
            </div>
            <hr style="border: 1px solid #ffffff; margin: 15px 0;">
            <div>SENS ADVISOR TECHNICAL DOCUMENTATION | © 2025 ALL RIGHTS RESERVED</div>
        </footer>
    </div>
</body>
</html>